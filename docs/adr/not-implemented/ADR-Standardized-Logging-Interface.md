# ADR: Standardized Logging Interface

**Driver:** James Wiesebron
**Approver:** TBD
**Contributors:** James Wiesebron, Claude (AI Pair Programming)
**Informed:** Engineering teams
**Proposed:** November 2025
**Status:** Draft

## Table of Contents

- [Context](#context)
- [Problem Statement](#problem-statement)
- [Decision](#decision)
- [OpenTelemetry Alignment](#opentelemetry-alignment)
- [High-Level Design](#high-level-design)
- [Structured Log Format](#structured-log-format)
- [Tool Wrappers](#tool-wrappers)
- [Model Output Capture](#model-output-capture)
- [GCP Cloud Logging Integration](#gcp-cloud-logging-integration)
- [Consequences](#consequences)
- [Alternatives Considered](#alternatives-considered)
- [Implementation Plan](#implementation-plan)

## Context

### Background

The jib system consists of multiple components across host and container environments:

| Component Type | Location | Examples |
|----------------|----------|----------|
| Host services | `host-services/` | github-watcher, slack-receiver, context-sync |
| Container scripts | `jib-container/` | jib CLI, PR helpers, discovery tools |
| Analysis tools | `host-services/analysis/` | codebase-analyzer, conversation-analyzer |

Currently, all components use `print()` statements for output with inconsistent formatting:
- No structured data format
- No severity levels
- No correlation between related operations
- No machine-parseable output for debugging
- No capture of Claude Code model output

### Current State

```python
# Current pattern (github-watcher.py)
print(f"  gh command failed: {' '.join(args)}")
print(f"  stderr: {e.stderr}")
print(f"  Invoking jib: {task_type} for {context.get('repository', 'unknown')}")
```

This approach has several limitations:
1. **Debugging**: Hard to filter and search logs
2. **Correlation**: No way to trace related operations across services
3. **Monitoring**: Cannot set up alerts on specific events
4. **GCP Integration**: Not compatible with Cloud Logging structured format
5. **Model Output**: No capture of full Claude Code responses

### Scope

**In Scope:**
- Python logging library for host and container scripts
- Structured JSON log format compatible with GCP Cloud Logging
- Tool wrappers for critical commands (bd, git, gh, claude)
- Model output capture mechanism
- Migration path for existing scripts

**Out of Scope:**
- Shell script logging (bash scripts continue using echo)
- Log aggregation infrastructure (handled by GCP)
- Real-time monitoring dashboards (future ADR)

## Problem Statement

**We need consistent, structured logging across all jib components that supports debugging today and GCP Cloud Logging in production.**

Requirements:

1. **Debugging Support**: Filter logs by service, severity, operation type
2. **Structured Format**: Machine-parseable JSON with consistent fields
3. **Tool Visibility**: Capture all invocations of critical tools (bd, git, gh)
4. **Model Output**: Capture full Claude Code model responses
5. **GCP Ready**: Compatible with Cloud Logging structured log format
6. **Low Friction**: Easy to adopt in existing scripts

## Decision

**Implement a shared `jib_logging` Python library that provides structured JSON logging, tool wrappers, and model output capture.**

### Core Principles

1. **Structured by Default**: All logs are JSON with consistent fields
2. **Context Propagation**: Correlation IDs flow through related operations
3. **Tool Transparency**: Wrappers log all critical tool usage
4. **Human Readable**: Development mode with formatted console output
5. **GCP Native**: Direct compatibility with Cloud Logging
6. **OpenTelemetry Aligned**: Compatible with emerging GenAI observability standards

## OpenTelemetry Alignment

### GenAI Semantic Conventions

The OpenTelemetry community has standardized semantic conventions for GenAI/LLM observability. The `jib_logging` library aligns with these conventions to ensure compatibility with the broader observability ecosystem.

**Key Standards:**
- [OpenTelemetry GenAI Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/) - Official spec for LLM telemetry
- [Agent-Specific Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-agent-spans/) - Spans for GenAI agent calls
- [Logs Specification](https://opentelemetry.io/docs/concepts/signals/logs/) - Structured log format requirements

### MELT Framework Integration

The logging interface is designed as part of a unified MELT (Metrics, Events, Logs, Traces) observability approach:

| Signal | Purpose | jib_logging Support |
|--------|---------|---------------------|
| **Metrics** | Quantitative measurements (token counts, latencies) | Extracted from structured logs |
| **Events** | Discrete occurrences (task started, PR created) | Logged with event-specific fields |
| **Logs** | Detailed context and debugging | Primary output of this library |
| **Traces** | Request flow across services | Correlation via traceId/spanId |

### Trace Correlation

All log entries include OpenTelemetry trace context for correlation:

```json
{
  "traceId": "0af7651916cd43dd8448eb211c80319c",
  "spanId": "b7ad6b7169203331",
  "traceFlags": "01",
  ...
}
```

This enables:
1. Linking logs to distributed traces
2. Filtering logs for a specific request/task
3. Integration with trace-aware observability platforms (Langfuse, Phoenix, etc.)

### Configuration

The library respects OpenTelemetry configuration patterns:

```bash
# Enable experimental semantic conventions
export OTEL_SEMCONV_STABILITY_OPT_IN=genai

# Configure trace context propagation
export OTEL_PROPAGATORS=tracecontext,baggage

# Set service identification
export OTEL_SERVICE_NAME=jib-github-watcher
export OTEL_RESOURCE_ATTRIBUTES=deployment.environment=production
```

### GenAI-Specific Attributes

For LLM operations, logs include standardized GenAI attributes:

| Attribute | Type | Description |
|-----------|------|-------------|
| `gen_ai.system` | string | LLM provider ("anthropic") |
| `gen_ai.request.model` | string | Model identifier |
| `gen_ai.usage.input_tokens` | int | Prompt token count |
| `gen_ai.usage.output_tokens` | int | Completion token count |
| `gen_ai.response.finish_reasons` | string[] | Why generation stopped |

Example log entry for Claude interaction:

```json
{
  "timestamp": "2025-11-28T12:34:56.789Z",
  "severity": "INFO",
  "message": "Claude Code response completed",
  "traceId": "0af7651916cd43dd8448eb211c80319c",
  "spanId": "b7ad6b7169203331",
  "gen_ai.system": "anthropic",
  "gen_ai.request.model": "claude-sonnet-4-5-20250929",
  "gen_ai.usage.input_tokens": 1500,
  "gen_ai.usage.output_tokens": 800,
  "gen_ai.response.finish_reasons": ["end_turn"],
  "context": {
    "task_id": "bd-xyz789",
    "task_type": "pr_fix"
  }
}
```

## High-Level Design

### Architecture Overview

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              jib_logging Library                              │
│                                                                               │
│  ┌─────────────────────┐  ┌─────────────────────┐  ┌─────────────────────┐  │
│  │    JibLogger        │  │   ToolWrappers      │  │  ModelCapture       │  │
│  │                     │  │                     │  │                     │  │
│  │  - Structured JSON  │  │  - bd wrapper       │  │  - Claude output    │  │
│  │  - Severity levels  │  │  - git wrapper      │  │  - Token usage      │  │
│  │  - Context fields   │  │  - gh wrapper       │  │  - Response time    │  │
│  │  - GCP format       │  │  - claude wrapper   │  │  - Error capture    │  │
│  │                     │  │                     │  │                     │  │
│  └─────────────────────┘  └─────────────────────┘  └─────────────────────┘  │
│                                      │                                        │
│                                      ▼                                        │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                         Output Handlers                                │   │
│  │                                                                        │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────────┐   │   │
│  │  │   Console    │  │    File      │  │    GCP Cloud Logging     │   │   │
│  │  │  (dev mode)  │  │  (local)     │  │    (production)          │   │   │
│  │  └──────────────┘  └──────────────┘  └──────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Library Location

```
james-in-a-box/
├── shared/
│   └── jib_logging/
│       ├── __init__.py           # Public API
│       ├── logger.py             # JibLogger class
│       ├── formatters.py         # JSON and console formatters
│       ├── context.py            # Context management
│       ├── wrappers/
│       │   ├── __init__.py
│       │   ├── bd.py             # Beads wrapper
│       │   ├── git.py            # Git wrapper
│       │   ├── gh.py             # GitHub CLI wrapper
│       │   └── claude.py         # Claude Code wrapper
│       └── model_capture.py      # Model output capture
```

Both host services and container scripts can import from this shared location.

## Structured Log Format

### Base Log Entry

All log entries include these fields:

```json
{
  "timestamp": "2025-11-28T12:34:56.789Z",
  "severity": "INFO",
  "message": "Human-readable message",
  "service": "github-watcher",
  "component": "pr_checker",
  "environment": "container",

  "traceId": "0af7651916cd43dd8448eb211c80319c",
  "spanId": "b7ad6b7169203331",
  "traceFlags": "01",

  "context": {
    "task_id": "bd-xyz789",
    "repository": "jwbron/james-in-a-box",
    "pr_number": 123
  },

  "labels": {
    "app": "jib",
    "version": "1.0.0"
  }
}
```

**Note:** The `traceId` and `spanId` fields follow the [W3C Trace Context](https://www.w3.org/TR/trace-context/) specification, enabling correlation with distributed traces across services.

### GCP Cloud Logging Compatibility

The format maps directly to [GCP structured logging](https://cloud.google.com/logging/docs/structured-logging):

| jib_logging Field | GCP Field | Purpose |
|-------------------|-----------|----------|
| `severity` | `severity` | Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) |
| `message` | `message` | Human-readable text |
| `timestamp` | `timestamp` | ISO 8601 format |
| `traceId` | `logging.googleapis.com/trace` | Distributed trace ID |
| `spanId` | `logging.googleapis.com/spanId` | Span within trace |
| `labels` | `logging.googleapis.com/labels` | Filterable metadata |
| `context.*` | `jsonPayload.*` | Structured data |
| `gen_ai.*` | `jsonPayload.gen_ai.*` | OpenTelemetry GenAI attributes |

### Severity Levels

| Level | Use Case | Example |
|-------|----------|----------|
| DEBUG | Detailed diagnostic info | "Checking PR #123 for failures" |
| INFO | Normal operations | "PR created successfully" |
| WARNING | Recoverable issues | "Rate limit approaching, backing off" |
| ERROR | Failed operations | "GitHub API returned 500" |
| CRITICAL | System-level failures | "Cannot connect to GitHub" |

## Tool Wrappers

### Purpose

Tool wrappers intercept calls to critical commands and:
1. Log the invocation with full arguments
2. Capture stdout/stderr
3. Record timing and exit codes
4. Propagate correlation context

### Wrapped Tools

| Tool | Why Wrap | What to Capture |
|------|----------|------------------|
| `bd` | Track task state changes | Command, task_id, status changes |
| `git` | Audit repository operations | Command, repo, branch, commit SHA |
| `gh` | Track GitHub API usage | Command, repo, PR number, response |
| `claude` | Capture model interactions | Prompt (summary), response, tokens, timing |

### Wrapper Implementation Pattern

```python
# Usage in scripts
from jib_logging.wrappers import git, bd, gh

# Instead of:
# subprocess.run(["git", "push", "origin", "main"])

# Use:
result = git.push("origin", "main")
# Automatically logs:
# {
#   "severity": "INFO",
#   "message": "git push completed",
#   "tool": "git",
#   "command": ["git", "push", "origin", "main"],
#   "exit_code": 0,
#   "duration_ms": 1234,
#   "context": {"repository": "jwbron/james-in-a-box", "branch": "main"}
# }
```

### bd (Beads) Wrapper

The beads wrapper captures task lifecycle:

```json
{
  "severity": "INFO",
  "message": "Task status updated",
  "tool": "bd",
  "command": ["bd", "update", "bd-abc123", "--status", "done"],
  "task_id": "bd-abc123",
  "previous_status": "in_progress",
  "new_status": "done",
  "duration_ms": 45
}
```

### git Wrapper

The git wrapper captures repository operations:

```json
{
  "severity": "INFO",
  "message": "Git commit created",
  "tool": "git",
  "command": ["git", "commit", "-m", "Add feature X"],
  "repository": "jwbron/james-in-a-box",
  "branch": "feature/logging",
  "commit_sha": "abc1234",
  "files_changed": 5,
  "duration_ms": 234
}
```

### gh (GitHub CLI) Wrapper

The gh wrapper captures API interactions:

```json
{
  "severity": "INFO",
  "message": "Pull request created",
  "tool": "gh",
  "command": ["gh", "pr", "create", "--title", "Add logging"],
  "repository": "jwbron/james-in-a-box",
  "pr_number": 125,
  "pr_url": "https://github.com/jwbron/james-in-a-box/pull/125",
  "duration_ms": 1567
}
```

## Model Output Capture

### Purpose

Capture full Claude Code model output for:
1. Debugging agent behavior
2. Cost tracking (token usage)
3. Performance analysis (response time)
4. Quality analysis (conversation patterns)

### Capture Strategy

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Model Output Capture                                │
│                                                                               │
│  ┌─────────────────────┐                                                     │
│  │   Claude Code       │                                                     │
│  │   (claude CLI)      │                                                     │
│  └──────────┬──────────┘                                                     │
│             │                                                                 │
│             ▼                                                                 │
│  ┌─────────────────────┐      ┌─────────────────────────────────────────┐  │
│  │   claude wrapper    │──────►  model_output.jsonl                      │  │
│  │                     │      │  (append-only log file)                  │  │
│  │  - Capture stdout   │      │                                          │  │
│  │  - Parse JSON       │      │  {"timestamp": "...", "prompt": "...",   │  │
│  │  - Extract tokens   │      │   "response": "...", "tokens": {...}}    │  │
│  │  - Measure timing   │      │                                          │  │
│  └─────────────────────┘      └─────────────────────────────────────────┘  │
│                                                                               │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Model Output Log Entry

Using OpenTelemetry GenAI semantic conventions for standardized observability:

```json
{
  "timestamp": "2025-11-28T12:34:56.789Z",
  "severity": "INFO",
  "message": "Claude Code response captured",
  "traceId": "0af7651916cd43dd8448eb211c80319c",
  "spanId": "b7ad6b7169203331",

  "gen_ai.system": "anthropic",
  "gen_ai.request.model": "claude-sonnet-4-5-20250929",
  "gen_ai.usage.input_tokens": 1500,
  "gen_ai.usage.output_tokens": 800,
  "gen_ai.response.finish_reasons": ["end_turn"],

  "duration_ms": 4500,
  "context": {
    "task_id": "bd-xyz789",
    "task_type": "pr_fix"
  },
  "output_file": "/var/log/jib/model_output/2025-11-28/0af7651916cd43dd.json"
}
```

### Token Usage Tracking

Detailed token metrics enable cost visibility and optimization:

| Metric | Purpose | Alerting Threshold |
|--------|---------|-------------------|
| `gen_ai.usage.input_tokens` | Prompt size tracking | > 100K per request |
| `gen_ai.usage.output_tokens` | Response size tracking | > 50K per request |
| Daily token totals | Budget monitoring | Configurable per user |
| Cost estimates | Financial tracking | Based on model pricing |

Token data flows to cost dashboards and can trigger alerts when usage exceeds thresholds.

### Full Response Storage

Full model responses are stored separately (not in main log stream) due to size:

```
/var/log/jib/model_output/
├── 2025-11-28/
│   ├── abc123.json      # Full response for correlation_id abc123
│   ├── def456.json
│   └── index.jsonl      # Metadata index for the day
```

## GCP Cloud Logging Integration

### Local Development

In local/container mode, logs go to:
1. Console (human-readable format)
2. File (`/var/log/jib/jib.log` - JSON format)

### GCP Production

In GCP Cloud Run, logs automatically flow to Cloud Logging when written to stdout in the correct format.

```python
# The library auto-detects environment
from jib_logging import get_logger

logger = get_logger("github-watcher")

# Same code works in both environments:
logger.info("Processing PR", pr_number=123, repository="jwbron/james-in-a-box")

# Local: Pretty console output
# GCP: Structured JSON to Cloud Logging
```

### Log Router Configuration

```hcl
# terraform/infrastructure/logging.tf

resource "google_logging_project_sink" "jib_logs" {
  name        = "jib-log-sink"
  destination = "bigquery.googleapis.com/projects/${var.project}/datasets/jib_logs"

  filter = <<-EOT
    resource.type="cloud_run_revision"
    labels.app="jib"
  EOT
}
```

### Useful Queries

```sql
-- Find all errors in last hour
SELECT timestamp, severity, message, jsonPayload.context
FROM `project.jib_logs.cloudrun_requests`
WHERE severity = "ERROR"
  AND timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)

-- Trace a specific operation
SELECT *
FROM `project.jib_logs.cloudrun_requests`
WHERE jsonPayload.correlation_id = "abc123"
ORDER BY timestamp

-- Tool usage summary
SELECT
  jsonPayload.tool,
  COUNT(*) as invocations,
  AVG(jsonPayload.duration_ms) as avg_duration_ms
FROM `project.jib_logs.cloudrun_requests`
WHERE jsonPayload.tool IS NOT NULL
GROUP BY jsonPayload.tool
```

## Consequences

### Positive

1. **Debugging**: Filter and search logs by any field
2. **Tracing**: Follow operations across services via correlation_id
3. **Monitoring**: Set up alerts on error rates, tool failures
4. **Cost Visibility**: Track Claude API token usage
5. **GCP Ready**: Zero changes needed for Cloud Logging
6. **Audit Trail**: Complete record of tool invocations

### Negative

1. **Migration Effort**: Existing scripts need updates
2. **Disk Space**: JSON logs larger than plain text
3. **Learning Curve**: Developers need to learn new API
4. **Dependency**: New shared library to maintain

### Trade-offs

| Aspect | print() Statements | jib_logging |
|--------|-------------------|---------------|
| Setup complexity | None | Import + configure |
| Output format | Unstructured text | Structured JSON |
| Searchability | grep only | Field-based queries |
| GCP integration | Manual parsing | Native |
| Disk usage | Lower | Higher |
| Development speed | Faster initially | Faster long-term |

## Alternatives Considered

### Alternative 1: Python Standard Logging Only

**Approach:** Use Python's built-in `logging` module with JSON formatter

**Pros:**
- No new dependencies
- Familiar to Python developers

**Cons:**
- No tool wrappers
- No model output capture
- No context propagation
- Verbose configuration

**Rejected:** Doesn't address tool visibility or model capture requirements

### Alternative 2: Structured Logging Library (structlog)

**Approach:** Use existing library like `structlog`

**Pros:**
- Battle-tested
- Rich features
- Good documentation

**Cons:**
- Still need custom tool wrappers
- Additional dependency
- May have features we don't need

**Rejected:** Adds dependency without solving tool wrapper needs

### Alternative 3: Log to Database Directly

**Approach:** Write logs directly to PostgreSQL/Firestore

**Pros:**
- Immediately queryable
- No file management

**Cons:**
- Network dependency for logging
- Slower than file writes
- Complex failure handling

**Rejected:** Logging should not fail if database is unavailable

## Implementation Plan

### Phase 1: Core Library

1. Create `shared/jib_logging/` directory structure
2. Implement `JibLogger` with JSON formatting
3. Add console handler for development
4. Add file handler for local deployment
5. Basic tests

### Phase 2: Tool Wrappers

1. Implement `bd` wrapper
2. Implement `git` wrapper
3. Implement `gh` wrapper
4. Implement `claude` wrapper (basic)
5. Integration tests

### Phase 3: Model Capture

1. Implement model output capture
2. Add token tracking
3. Add response storage
4. Add performance metrics

### Phase 4: Migration

1. Update github-watcher to use new logging
2. Update slack-receiver
3. Update context-sync
4. Update container scripts
5. Documentation

### Phase 5: GCP Cloud Logging Integration

GCP-specific functionality (Cloud Logging output handler, log router configuration, BigQuery export) will be implemented as part of the GCP migration per [ADR-GCP-Deployment-Terraform](./ADR-GCP-Deployment-Terraform.md). This ensures:

1. GCP infrastructure is available before adding Cloud Logging integration
2. Logging changes are tested alongside other GCP components
3. Terraform configuration for log sinks can be added atomically

**Deferred to GCP Migration:**
- Cloud Logging output handler activation
- Log router/sink Terraform configuration
- BigQuery export for log analytics
- Production monitoring dashboards

## Related ADRs

| ADR | Relationship |
|-----|---------------|
| [ADR-GCP-Deployment-Terraform](./ADR-GCP-Deployment-Terraform.md) | Defines Cloud Run deployment where logs flow to Cloud Logging |
| [ADR-Internet-Tool-Access-Lockdown](./ADR-Internet-Tool-Access-Lockdown.md) | Tool wrappers complement gateway audit logging |
| [ADR-Autonomous-Software-Engineer](../in-progress/ADR-Autonomous-Software-Engineer.md) | Parent ADR defining debugging and observability needs |
| [ADR-Model-Agnostic-Architecture](./ADR-Model-Agnostic-Architecture.md) | Logging must support multi-provider LLM outputs for debugging and cost tracking |
| [ADR-LLM-Inefficiency-Reporting](ADR-LLM-Inefficiency-Reporting.md) | Structured logging enables trace collection and inefficiency detection described in that ADR |

---

**Last Updated:** 2025-11-28
**Status:** Draft - Awaiting Review
